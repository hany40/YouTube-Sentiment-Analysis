{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube API Comment Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import isodate\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "pd.set_option('display.colheader_justify', 'left')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "API_KEY = '' #<-- HIER API KEY EINFÜGEN\n",
    "CHANNEL_ID = 'UCNhxq7He5p-_FdBh0OaxcQg' #<-- CHANNEL ID VON NIKE https://www.youtube.com/@nike\n",
    "MIN_COMMENT_COUNT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtube_client():\n",
    "    return googleapiclient.discovery.build(\n",
    "        \"youtube\", \"v3\", developerKey=API_KEY\n",
    "    )\n",
    "youtube = youtube_client() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Video Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_ids_from_channel(channel_id):\n",
    "    youtube = youtube_client()\n",
    "    video_ids = []<\n",
    "\n",
    "    response = youtube.channels().list(part=\"contentDetails\", id=channel_id).execute()\n",
    "    uploads_playlist_id = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "\n",
    "    next_page_token = None\n",
    "    while True:\n",
    "        response = youtube.playlistItems().list(\n",
    "            part=\"snippet\", playlistId=uploads_playlist_id, maxResults=50, pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['snippet']['resourceId']['videoId'])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = get_video_ids_from_channel(CHANNEL_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Video Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(video_id):\n",
    "    youtube = youtube_client()\n",
    "    response = youtube.videos().list(part=\"snippet,contentDetails\", id=video_id).execute()\n",
    "\n",
    "    for item in response['items']:\n",
    "        title = item['snippet']['title']\n",
    "        video_id = item['id']\n",
    "        raw_duration = item['contentDetails']['duration']\n",
    "        duration = isodate.parse_duration(raw_duration).total_seconds()\n",
    "        raw_date = item['snippet']['publishedAt']\n",
    "        upload_date = datetime.strptime(raw_date, '%Y-%m-%dT%H:%M:%SZ').strftime('%d.%m.%Y')\n",
    "\n",
    "    video_detail = {\n",
    "        'Video ID': video_id,\n",
    "        'Title': title,\n",
    "        'Duration': duration,\n",
    "        'Upload Date': upload_date\n",
    "        }\n",
    "    return video_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_details = []\n",
    "for video_id in video_ids:\n",
    "    print(video_id)\n",
    "    videos_details.append(get_video_details(video_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Comments per Video ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(video_id):\n",
    "    youtube = youtube_client()\n",
    "    comments = []\n",
    "    try:\n",
    "        request = youtube.commentThreads().list(part=\"snippet\", videoId=video_id, maxResults=10000)\n",
    "        while request:\n",
    "            response = request.execute()\n",
    "\n",
    "            for item in response['items']:\n",
    "                comment = item['snippet']['topLevelComment']['snippet']\n",
    "                raw_date = comment['publishedAt']\n",
    "                date = datetime.strptime(raw_date, '%Y-%m-%dT%H:%M:%SZ').strftime('%d.%m.%Y')\n",
    "                comments.append({\n",
    "                    'Video ID': video_id,\n",
    "                    'authorDisplayName': comment['authorDisplayName'],\n",
    "                    'date': date,\n",
    "                    'likeCount': comment['likeCount'],\n",
    "                    'comment': comment['textDisplay']\n",
    "                })\n",
    "\n",
    "            request = youtube.commentThreads().list_next(request, response)\n",
    "\n",
    "    except googleapiclient.errors.HttpError as e:\n",
    "        if e.resp.status == 403:\n",
    "            print(f\"Kommentare für Video {video_id} sind deaktiviert.\")\n",
    "        else:\n",
    "            print(f\"Fehler beim Abrufen der Kommentare für Video {video_id}: {e}\")\n",
    "\n",
    "    if comments:\n",
    "        return comments\n",
    "    else:\n",
    "        return None, 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "for video in videos_details:\n",
    "    video_comments = get_comments(video['Video ID'])\n",
    "    if len(video_comments) > MIN_COMMENT_COUNT:\n",
    "        comments.extend(video_comments)\n",
    "    else: \n",
    "        videos_details.remove(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataFrame(details, comments) -> pd.DataFrame:\n",
    "    df_detail = pd.DataFrame(details)\n",
    "    df_comments = pd.DataFrame(comments)\n",
    "    df = pd.merge(df_detail, df_comments, on='Video ID', how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = createDataFrame(videos_details, comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        t = 'http' if t.startswith('href') else t\n",
    "        t = '' if t.startswith('<a') else t\n",
    "        t = '' if t.startswith('<br>') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment'] = df['comment'].apply(lambda x: preprocess_text(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text):\n",
    "    translated_text = str(GoogleTranslator(source='auto', target='en').translate(text)) #if pd.notna(text) else text\n",
    "    if len(translated_text) > 0: \n",
    "        return translated_text\n",
    "    else: \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"comment_en\"] = df[\"comment\"].apply(lambda x: translate_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv',encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
